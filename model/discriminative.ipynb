{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'kernel.XInteractiveShell' object has no attribute 'events'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "In  \u001b[0;34m[1]\u001b[0m:\nLine \u001b[0;34m1\u001b[0m:     %load_ext autoreload\n",
      "File \u001b[0;34m<decorator-gen-57>\u001b[0m, in \u001b[0;32mload_ext\u001b[0m:\nLine \u001b[0;34m2\u001b[0m:     \n",
      "File \u001b[0;34m/Users/guydavidson/opt/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/magic.py\u001b[0m, in \u001b[0;32m<lambda>\u001b[0m:\nLine \u001b[0;34m187\u001b[0m:   call = \u001b[34mlambda\u001b[39;49;00m f, *a, **k: f(*a, **k)\n",
      "File \u001b[0;34m/Users/guydavidson/opt/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/magics/extension.py\u001b[0m, in \u001b[0;32mload_ext\u001b[0m:\nLine \u001b[0;34m33\u001b[0m:    res = \u001b[36mself\u001b[39;49;00m.shell.extension_manager.load_extension(module_str)\n",
      "File \u001b[0;34m/Users/guydavidson/opt/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/extensions.py\u001b[0m, in \u001b[0;32mload_extension\u001b[0m:\nLine \u001b[0;34m87\u001b[0m:    \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m._call_load_ipython_extension(mod):\n",
      "File \u001b[0;34m/Users/guydavidson/opt/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/extensions.py\u001b[0m, in \u001b[0;32m_call_load_ipython_extension\u001b[0m:\nLine \u001b[0;34m134\u001b[0m:   mod.load_ipython_extension(\u001b[36mself\u001b[39;49;00m.shell)\n",
      "File \u001b[0;34m/Users/guydavidson/opt/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/extensions/autoreload.py\u001b[0m, in \u001b[0;32mload_ipython_extension\u001b[0m:\nLine \u001b[0;34m549\u001b[0m:   ip.events.register(\u001b[33m'\u001b[39;49;00m\u001b[33mpre_run_cell\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, auto_reload.pre_run_cell)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'kernel.XInteractiveShell' object has no attribute 'events'\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guydavidson/opt/anaconda3/envs/torch/lib/python3.8/site-packages/mxnet/optimizer/optimizer.py:163: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n",
      "  warnings.warn('WARNING: New optimizer %s.%s is overriding '\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "import mlm\n",
    "from mlm.scorers import MLMScorerPT \n",
    "from mlm.models import get_pretrained\n",
    "\n",
    "import mxnet as mx\n",
    "ctxs = [mx.cpu()]\n",
    "\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "from dataset_orm import *\n",
    "from wordbank_tasks import *\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTES\n",
    "\n",
    "* **TODO**: verify the surgery I did to the mlm.scorers codebase to accept RoBERTa is legit\n",
    "* If we want other models, we'll have to add them there, too, perhaps with a bit more work if their output format is very different\n",
    "* The function below implements the very basic test. Next steps I can see us wanting to do:\n",
    "    * Combine it with sentences from the real data\n",
    "    * Check at least two alternative word-replacement strategies (within category, between categories)\n",
    "    * Write more of a pipeline that samples words, sentences, replacement words for each sentence, and spits out scorers\n",
    "* Open questions:\n",
    "    * How do we measure how well the model did? Rank of the correct sentence? NLL difference from correct and other best-performing sentence? Both? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Created scorer of class 'MLMScorerPT'.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "WARNING:root:Created scorer of class 'MLMScorerPT'.\n"
     ]
    }
   ],
   "source": [
    "def scorer_from_transformers_checkpoint(checkpotint_name, contexts):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(checkpotint_name)\n",
    "    model = AutoModelForMaskedLM.from_pretrained(checkpotint_name)\n",
    "    return MLMScorerPT(model, None, tokenizer, contexts)\n",
    "\n",
    "roberta_scorer = scorer_from_transformers_checkpoint('nyu-mll/roberta-base-100M-1', ctxs)\n",
    "bert_scorer = scorer_from_transformers_checkpoint('bert-base-uncased', ctxs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_FILE = 'wordbank.db'\n",
    "DB_PATH = pathlib.Path(os.getcwd()).parent.absolute() / 'data' / DB_FILE\n",
    "engine = create_engine(f'sqlite:///{DB_PATH}')\n",
    "Session = sessionmaker(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()\n",
    "discriminative_task_all_words(\n",
    "    session_maker=Session, n_sentences_per_word=5, n_alternative_words=5,\n",
    "    model_names=('bert', 'roberta'), model_scorers=[bert_scorer, roberta_scorer],\n",
    "    criterion_func=smallest_nll_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()\n",
    "table_word = session.query(WordbankWord).filter(WordbankWord.word == 'table').one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_query = session.query(WordbankWord.id, WordbankWord.word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0, 1, 2), (10, 11, 12))\n",
      "(('a', 'b', 'c'), ('d', 'e', 'f'))\n"
     ]
    }
   ],
   "source": [
    "l = [[(0, 'a'), (1, 'b'), (2, 'c')], [(10, 'd'), (11, 'e'), (12, 'f')]]\n",
    "ids, words = list(zip(*[list(zip(*x)) for x in l]))\n",
    "print(ids)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 2), ('a', 'b', 'c')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*[(0, 'a'), (1, 'b'), (2, 'c')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "words_df = pd.read_csv('../data/worbank_with_category.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(s.split(' ')) > 1 for s in words_df.value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  a lot\n",
       "6               all gone\n",
       "22               baa baa\n",
       "25     babysitter's name\n",
       "47          belly button\n",
       "111     child's own name\n",
       "114            choo choo\n",
       "199         french fries\n",
       "207          gas station\n",
       "213        give me five!\n",
       "219             go potty\n",
       "220       gonna get you!\n",
       "221             going to\n",
       "224               got to\n",
       "230          green beans\n",
       "233              have to\n",
       "257           high chair\n",
       "274            ice cream\n",
       "299           lawn mower\n",
       "301               let me\n",
       "309          living room\n",
       "350              need to\n",
       "352              next to\n",
       "355          night night\n",
       "369            on top of\n",
       "378              boo boo\n",
       "388        peanut butter\n",
       "398           pet's name\n",
       "409           play dough\n",
       "410             play pen\n",
       "421          potato chip\n",
       "436          quack quack\n",
       "447        rocking chair\n",
       "496              so big!\n",
       "538            thank you\n",
       "548    this little piggy\n",
       "581          turn around\n",
       "584                uh oh\n",
       "599              want to\n",
       "601      washing machine\n",
       "619            woof woof\n",
       "630              yum yum\n",
       "Name: value, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.value[[len(s.split(' ')) > 1 for s in words_df.value]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
